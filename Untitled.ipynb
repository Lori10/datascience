{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - What is the difference between model training parameters and hyperparameters ?\n",
    "Training parameters like weights in Gradient Descent are parameters that are learned from the model during training. Using weight updation of Gradient Descent they keep changing during training phase while hyperparametrs are parameter whose value need to be set before we start training and during training they do not change. <br>\n",
    "In deep learning training parameters are nr of layers, nr of neurons in each layer, activation function while hyperparameters are learning rate, nr of epochs, batch size, momentum etc.\n",
    "\n",
    "Le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
