{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How it works ?\n",
    "\n",
    "<img src='images/sigmoid.png' width=\"400\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What Are the Basic Assumption?\n",
    "1. Linear Relation between independent features and the log odds. In Linear Regression independent and dependent variables are related linearly. But Logistic Regression needs that independent variables are linearly related to the log odds (log(p/(1-p)).\n",
    "2. Independence : Features are independent\n",
    "3. We should use LogisticRegression when data is linearly separable (for more complicated relationship between the features LogisitcRegression would not work well)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Advantages\n",
    "\n",
    "1. Logistic Regression are very easy to understand\n",
    "2. It requires less training\n",
    "3. Good accuracy for many simple data sets and it performs well when the dataset is linearly separable.\n",
    "4. It makes no assumptions about distributions of classes in feature space.\n",
    "6. Logistic regression is easier to implement, interpret, and very efficient to train.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Disadvantages\n",
    "1. Sometimes Lot of Feature Engineering Is required\n",
    "2. If the independent features are correlated it may affect performance\n",
    "3. It is often quite prone to noise and overfitting\n",
    "4. If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting.\n",
    "5. \tNon-linear problems canâ€™t be solved with logistic regression because it has a linear decision surface. Linearly separable data is rarely found in real-world scenarios.\n",
    "6. It is tough to obtain complex relationships using logistic regression. More powerful and compact algorithms such as Neural Networks can easily outperform this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Whether Feature Scaling is required?\n",
    "No, feature scaling does not affect the performance of a logistic regression model as long as we do not perform logistic regression with regularization. In penalized logistic regression, scaling does affect it. Upscaled variables become more penalized, i.e. have coefficients shrunk more towards zero.\n",
    "\n",
    "### 5. Missing Values\n",
    "Sensitive to missing values.\n",
    "\n",
    "### 6. Impact of outliers?\n",
    "Logistic Regression is sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and Underfitting\n",
    "Logistic regression is proned to over-fitting but it can overfit in high dimensional datasets.\n",
    "To avoid overfitting with Logistic Regression we can consider Regularization (L1 and L2) techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
