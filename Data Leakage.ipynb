{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Data Leakage in Machine Learning? <br>\n",
    "\n",
    "Data leakage is when information from outside the training dataset is used to create the model. This additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the mode being constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is Data Leakage a Problem ? \n",
    "1. It is a problem if you are running a machine learning competition. Top models will use the leaky data rather than be good general model of the underlying problem.\n",
    "2. It is a problem when you are a company providing your data. Reversing an anonymization and obfuscation can result in a privacy breach that you did not expect.\n",
    "3. It is a problem when you are developing your own predictive models. You may be creating overly optimistic models that are practically useless and cannot be used in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do I have Data Leakage? How to detect it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to know you have data leakage is if you are achieving performance on test set that seems a little too good to be true. Data Leakage usually shows off when the model has a good performance on test set (since the model had some information about this test data during training) but when we test it on new unseen data after deployment it performs bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques to avoid Data Leakage ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform data preparation within your cross validation folds. We should re-prepare or re-calculate any required data preparation within your cross validation folds (for each train and test kfold perform all these tasks) including tasks like imputing missing values, feature selection, outlier removal, encoding categorical features, feature scaling and projection methods for dimensionality reduction, and more\n",
    "2. Hold back a test dataset for final sanity check of your developed models. (dataset that model has never seen during training)\n",
    "\n",
    "**Note:** <br>\n",
    "If during training we keep the cross validation dataset completely unseen and untouchable (which means we apply every task of data preprocessing separately in each training kfold and then on each cross validation kfold) we dont need to keep another test set to test the model performance. If during training we are not having 100% data leakage like for example some preprocessing tasks we perform on the entire training set (before doing cross validation) we should keep another test set untouchable to check how the model performns on completely new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** <br>\n",
    "https://machinelearningmastery.com/data-leakage-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
